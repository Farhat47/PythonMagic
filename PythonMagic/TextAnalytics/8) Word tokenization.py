from nltk.tokenize import word_tokenize
sentence = "This is a sample sentence showing the word tokenization."
word_tokens = word_tokenize(sentence)
print(sentence)
print(word_tokens)
